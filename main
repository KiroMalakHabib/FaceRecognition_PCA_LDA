#functions#
#1-load photos.
def load_photos():
  data_matrix = np.zeros((400,10304))
  labels = np.zeros((400,1))
  data_directory = "/content/drive/My Drive/orl_dataset"
  #j is for the row number
  j = 0
  #i for the label
  i = 0
  for folder_name in sorted(os.listdir(data_directory)):
    i+=1
    folder_path = os.path.join(data_directory,folder_name)
    for image in sorted(os.listdir(folder_path)):
      image_path = os.path.join(folder_path,image)
      new_image = cv2.imread(image_path,0)
      data_matrix[j,:] = new_image.flatten()
      labels[j] = i
      j+=1
  return data_matrix, labels
  
  #2-split odds and evens
def split_data(data_matrix, labels):
  training_data = data_matrix[::2]
  testing_data = data_matrix[1::2]
  training_labels = labels[::2]
  testing_labels = labels[1::2]
  return training_data, testing_data, training_labels, testing_labels
  
  #split 70% training 30% testing
def split_extra(data_matrix, labels):
  training_data = np.zeros((280,10304))
  testing_data = np.zeros((120,10304))
  training_labels = np.zeros((280,1))
  testing_labels = np.zeros((120,1))
  j = 0
  train_iterator = 0
  test_iterator = 0
  for i1 in range(400):
    if j == 10:
      j = 0
    if j < 7:
      for i2 in range(10304):
        training_data[train_iterator][i2] = data_matrix[i1][i2]
        training_labels[train_iterator][0] = labels[i1][0]
      train_iterator += 1
    elif j < 10:
      for i2 in range(10304):
        testing_data[test_iterator][i2] = data_matrix[i1][i2]
        testing_labels[test_iterator][0] = labels[i1][0]
      test_iterator += 1
    j += 1
  return training_data, testing_data, training_labels, testing_labels
  
  
#   Classification using LDA    #
#   function to calc. calsses mean    #
def calc_classes_mean_matrix(train_data,train_labels):
    means = np.zeros((40,10304)) 
    train_test_split_ratio = 5
    
    for i in range(1,41):
        temp = np.where(train_labels == i)[0]
        temp_sum = np.zeros((1,10304)) 
        for j in range (train_test_split_ratio):
           temp_sum += train_data[temp[j],:]        
            
        means[i-1,:] = temp_sum / train_test_split_ratio
    return means      #40*10304

#     overall mean for classes mean     #
def calc_overall_mean_matrix(classes_means):
    temp_sum = np.zeros((1,10304)) 
    for i in range(0,40):
        temp_sum +=classes_means[i,:]
    overall_mean = temp_sum / 40
    
    return overall_mean.T     #10304*1

#     matrix of the overall scatter between all the 40 classes      #
def calc_between_class_scatter_matrix(classes_means,overall_mean):
    n=5
    #10304*10304
    Sb = np.zeros((classes_means.shape[1],classes_means.shape[1]))
    for i in range(classes_means.shape[0]):
        Sb = np.add(Sb,n* ((classes_means[i] - overall_mean) * (classes_means[i] - overall_mean).T))
    return Sb     #10304*10304
#     centrelization      #
def calc_center_class_matrix(train_data,train_labels,classes_means):
    Z = np.zeros(train_data.shape)
    
    for i in range(train_data.shape[0]):
        Z[i,:] = train_data[i,:] - classes_means[int(train_labels[i])-1,:]

    return Z
#S=Z.T*Z
def calc_class_scatter_matrix(Z):
    S = np.zeros((10304,10304))
    S = np.dot(Z.T,Z)
    return S 

def reduce_data_dimensionality(train_data,test_data, vectors):
    train_data_dimensionally_reduced = np.zeros((200,40)) 
    test_data_dimensionally_reduced = np.zeros((200,40)) 
    
    i=0
    for img in train_data:
        train_data_dimensionally_reduced[i,:]=np.dot(img,vectors)
        i+=1
    i=0
    for img in test_data:
        test_data_dimensionally_reduced[i,:] = np.dot(img,vectors)
        i+=1
        
    return train_data_dimensionally_reduced,test_data_dimensionally_reduced

def reduce_data_dimensionality_extra(train_data,test_data, vectors):
    train_data_dimensionally_reduced = np.zeros((280,40)) 
    test_data_dimensionally_reduced = np.zeros((120,40)) 
    
    i=0
    for img in train_data:
        train_data_dimensionally_reduced[i,:]=np.dot(img,vectors)
        i+=1
    i=0
    for img in test_data:
        test_data_dimensionally_reduced[i,:] = np.dot(img,vectors)
        i+=1
        
    return train_data_dimensionally_reduced,test_data_dimensionally_reduced
  
data_matrix, labels = load_photos()#run once, takes alot of time.
print(data_matrix)

#############################################################################################################
training_data, testing_data, training_labels, testing_labels = split_data(data_matrix, labels)#change it with dimentionality
#############################################################################################################
print(training_labels.shape)
print(testing_labels.shape)
training_labels = training_labels.flatten()
testing_labels = testing_labels.flatten()
print(training_data.shape)
print(testing_data.shape)


#Classification using PCA
alpha = np.array([0.8, 0.85, 0.9, 0.95])
#     computing means      #
mean_mat_train = np.mean(training_data, axis=0)
mean_mat_test = np.mean(testing_data, axis=0)
#     centerlizing data     #
norm = training_data - mean_mat_train
#     calc. cov. train mat.     #
cov_train = np.cov(norm.T)
#     calc. train eigenvalues & eigenvectors      #
#     IT TAKES ALOT OF TIME SO RUN ONCE     #
values, vectors = np.linalg.eigh(cov_train)

flipped_values = np.flip(values)
flipped_vectors = np.fliplr(vectors)


assending_sum = 0
index = 0
sum_values = np.sum(flipped_values)
fr = 0
num_of_columns = np.zeros(4)
rotation = 0
for a in alpha:
  while fr < a:
    assending_sum += flipped_values[index]
    fr = assending_sum/sum_values
    index += 1
  num_of_columns[rotation] = index - 1
  rotation += 1
  
  
proj_train_mat_a1 = np.dot(training_data, flipped_vectors[: , 0:int(num_of_columns[0])])
proj_test_mat_a1 = np.dot(testing_data, flipped_vectors[:, 0:int(num_of_columns[0])])
proj_train_mat_a2 = np.dot(training_data, flipped_vectors[: , 0:int(num_of_columns[1])])
proj_test_mat_a2 = np.dot(testing_data, flipped_vectors[:, 0:int(num_of_columns[1])])
proj_train_mat_a3 = np.dot(training_data, flipped_vectors[: , 0:int(num_of_columns[2])])
proj_test_mat_a3 = np.dot(testing_data, flipped_vectors[:, 0:int(num_of_columns[2])])
proj_train_mat_a4 = np.dot(training_data, flipped_vectors[: , 0:int(num_of_columns[3])])
proj_test_mat_a4 = np.dot(testing_data, flipped_vectors[:, 0:int(num_of_columns[3])])


#1NN classifier
knn = KNeighborsClassifier(n_neighbors=1)
knn.fit(proj_train_mat_a1, training_labels)
predict_labels_a1 = knn.predict(proj_test_mat_a1)
accuarcy_a1 = metrics.accuracy_score(testing_labels, predict_labels_a1)
print(accuarcy_a1)

knn.fit(proj_train_mat_a2, training_labels)
predict_labels_a2 = knn.predict(proj_test_mat_a2)
accuarcy_a2 = metrics.accuracy_score(testing_labels, predict_labels_a2)
print(accuarcy_a2)

knn.fit(proj_train_mat_a3, training_labels)
predict_labels_a3 = knn.predict(proj_test_mat_a3)
accuarcy_a3 = metrics.accuracy_score(testing_labels, predict_labels_a3)
print(accuarcy_a3)

knn.fit(proj_train_mat_a4, training_labels)
predict_labels_a4 = knn.predict(proj_test_mat_a4)
accuarcy_a4 = metrics.accuracy_score(testing_labels, predict_labels_a4)
print(accuarcy_a4)

classes_mean = calc_classes_mean_matrix(training_data, training_labels)
overall_mean = calc_overall_mean_matrix(classes_mean)
Sb = calc_between_class_scatter_matrix(classes_mean, overall_mean)#run once takes alot of time

Z = calc_center_class_matrix(training_data, training_labels, classes_mean)
S = calc_class_scatter_matrix(Z)
W = np.dot(np.linalg.inv(S),Sb)#it takes alot of time run once.   s1+s2

lda_values, lda_vectors = scipy.linalg.eigh(W,eigvals=((10304-40),(10304-1)))#it takes alot of time run once.
############################################################################################################################################
train_data_dimensionally_reduced,test_data_dimensionally_reduced = reduce_data_dimensionality(training_data,testing_data, lda_vectors)#changr by changing traim/test dimentionality.
############################################################################################################################################

#     1st NN classifier     #
classifier = KNeighborsClassifier(n_neighbors=1)
classifier.fit(train_data_dimensionally_reduced, training_labels)
test_predict = classifier.predict(test_data_dimensionally_reduced)
lda_accuarcy = metrics.accuracy_score(testing_labels, test_predict)
print(lda_accuarcy)

#     classifier tuning for PCA     #
k_values = np.array([1, 3, 5, 7])
acc_all = np.zeros((4,4))
for i in range(len(k_values)):
  knn = KNeighborsClassifier(n_neighbors=k_values[i])

  knn.fit(proj_train_mat_a1, training_labels)
  predict_labels_a1 = knn.predict(proj_test_mat_a1)
  acc_all[i][0] = metrics.accuracy_score(testing_labels, predict_labels_a1)
  

  knn.fit(proj_train_mat_a2, training_labels)
  predict_labels_a2 = knn.predict(proj_test_mat_a2)
  acc_all[i][1] = metrics.accuracy_score(testing_labels, predict_labels_a2)

  knn.fit(proj_train_mat_a3, training_labels)
  predict_labels_a3 = knn.predict(proj_test_mat_a3)
  acc_all[i][2] = metrics.accuracy_score(testing_labels, predict_labels_a3)

  knn.fit(proj_train_mat_a4, training_labels)
  predict_labels_a4 = knn.predict(proj_test_mat_a4)
  acc_all[i][3] = metrics.accuracy_score(testing_labels, predict_labels_a4)
  
plt.title('Accuracy for alpha = 0.8')
plt.xlabel('K Value')
plt.ylabel('Accuracy %')
plt.plot(k_values, acc_all[0])

plt.title('Accuracy for alpha = 0.85')
plt.xlabel('K Value')
plt.ylabel('Accuracy %')
plt.plot(k_values, acc_all[1])

plt.title('Accuracy for alpha = 0.9')
plt.xlabel('K Value')
plt.ylabel('Accuracy %')
plt.plot(k_values, acc_all[2])

plt.title('Accuracy for alpha = 0.95')
plt.xlabel('K Value')
plt.ylabel('Accuracy %')
plt.plot(k_values, acc_all[3])

#     classifier tuning for LDA     #
lda_accuarcies = np.zeros(4)
for i in range(len(k_values)):
  classifier = KNeighborsClassifier(n_neighbors=k_values[i])
  classifier.fit(train_data_dimensionally_reduced, training_labels)
  test_predict = classifier.predict(test_data_dimensionally_reduced)
  lda_accuarcies[i] = metrics.accuracy_score(testing_labels, test_predict)

plt.title('Accuracy for LDA')
plt.xlabel('K Value')
plt.ylabel('Accuracy %')
plt.plot(k_values, lda_accuarcies)
print(lda_accuarcies)
